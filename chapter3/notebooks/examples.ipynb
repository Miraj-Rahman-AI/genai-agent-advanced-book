{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 Sample Code\n",
    "\n",
    "This notebook contains sample code for Chapter 3 of \"A Practical Introduction to AI Agents.\"\n",
    "\n",
    "**See `README.md` for environment setup (Python 3.12 is used).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "# This Notebook will import all libraries for the first time.\n",
    "\n",
    "# Basic Libraries\n",
    "import os\n",
    "import json\n",
    "from typing import TypedDict\n",
    "from itertools import islice\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# OpenAI Related\n",
    "from openai import OpenAI\n",
    "\n",
    "# Pydantic\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangChain Related\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "# LangGraph related\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# External library\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "# Jupyter Notebook library\n",
    "from IPython.display import Image, display\n",
    "\n",
    "load_dotenv() # Load the .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API Basics\n",
    "- This section covers the contents of \"3.1 OpenAI API Basics\" in the book.\n",
    "- Only sections with code examples are listed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 How to use OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Code Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the client\n",
    "client = OpenAI(\n",
    "api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Example of a Chat Completion API call\n",
    "response = client.chat.completions.create(\n",
    "model=\"gpt-4o\",\n",
    "messages=[{\"role\": \"user\", \"content\": \"Hello, what's the weather like today?\"}],\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(\"Response:\", response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the number of tokens consumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of tokens consumed\n",
    "tokens_used = response.usage\n",
    "print(\"Prompt Tokens:\", tokens_used.prompt_tokens)\n",
    "print(\"Completion Tokens:\", tokens_used.completion_tokens)\n",
    "print(\"Total Tokens:\", tokens_used.total_tokens)\n",
    "print(\"Completion_tokens_details:\", tokens_used.completion_tokens_details)\n",
    "print(\"Prompt_tokens_details:\", tokens_used.prompt_tokens_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.5 Structured Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json mode setting example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "model=\"gpt-4o\",\n",
    "response_format={\"type\": \"json_object\"},\n",
    "messages=[\n",
    "{\n",
    "\"role\": \"system\",\n",
    "\"content\": \"You are a helpful assistant designed to output JSON.\",\n",
    "},\n",
    "{\"role\": \"assistant\", \"content\": '{\"winner\": String}'},\n",
    "{\"role\": \"user\", \"content\": \"Who won the 2020 World Series?\"},\n",
    "],\n",
    ")\n",
    "\n",
    "response.choices[0].message.content\n",
    "\n",
    "# Example output\n",
    "# '{\"year\": 2020, \"winner\": \"Los Angeles Dodgers\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of Structured Outputs execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Pydantic model\n",
    "class Recipe(BaseModel):\n",
    "name: str\n",
    "servings: int\n",
    "ingredients: list[str]\n",
    "steps: list[str]\n",
    "\n",
    "# Call the Pydantic model corresponding to the Structured Outputs\n",
    "response = client.beta.chat.completions.parse(\n",
    "model=\"gpt-4o\",\n",
    "messages=[{\"role\": \"user\", \"content\": \"Please tell me the recipe for taco rice\"}],\n",
    "temperature=0,\n",
    "response_format=Recipe,\n",
    ")\n",
    "# Display the generated recipe information\n",
    "recipe = response.choices[0].message.parsed\n",
    "\n",
    "print(\"Recipe Name:\", recipe.name)\n",
    "print(\"Servings:\", recipe.servings)\n",
    "print(\"Ingredients:\", recipe.ingredients)\n",
    "print(\"Steps:\", recipe.steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use Function Calling\n",
    "- This section covers the contents of \"3.2 How to Use Function Calling\" in the book.\n",
    "- Only sections with code examples are listed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 How to use Function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy function to obtain weather information\n",
    "def get_weather(location):\n",
    "# Simplifies the actual API call\n",
    "weather_info = {\n",
    "\"Tokyo\": \"Sunny, temperature 25°C\",\n",
    "\"Osaka\": \"Cloudy, temperature 22°C\",\n",
    "\"Kyoto\": \"Rainy, temperature 18°C\",\n",
    "}\n",
    "return weather_info.get(location, \"Weather information not found\")\n",
    "\n",
    "# Initial user message\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is the weather in Tokyo?\"}]\n",
    "\n",
    "# Define the tool to provide to the model\n",
    "tools = [\n",
    "{\n",
    "\"type\": \"function\",\n",
    "\"function\": {\n",
    "\"name\": \"get_weather\",\n",
    "\"description\": \"Gets weather information for the specified location\",\n",
    "\"parameters\": {\n",
    "\"type\": \"object\",\n",
    "\"properties\": {\n",
    "\"location\": {\n",
    "\"type\": \"string\",\n",
    "\"description\": \"City name (e.g., Tokyo)\",\n",
    "},\n",
    "},\n",
    "\"required\": [\"location\"],\n",
    "},\n",
    "},\n",
    "}\n",
    "]\n",
    "\n",
    "# Initial API request to the model\n",
    "response = client.chat.completions.create(\n",
    "model=\"gpt-4o\",\n",
    "messages=messages,\n",
    "temperature=0,\n",
    "tools=tools,\n",
    "tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "# Process the model response\n",
    "response_message = response.choices[0].message\n",
    "messages.append(response_message)\n",
    "\n",
    "print(\"Response from the model:\")\n",
    "print(response_message)\n",
    "\n",
    "# Process the function call\n",
    "if response_message.tool_calls:\n",
    "for tool_call in response_message.tool_calls:\n",
    "if tool_call.function.name == \"get_weather\":\n",
    "function_args = json.loads(tool_call.function.arguments)\n",
    "print(f\"Function arguments: {function_args}\")\n",
    "weather_response = get_weather(location=function_args.get(\"location\"))\n",
    "messages.append(\n",
    "{\n",
    "\"tool_call_id\": tool_call.id,\n",
    "\"role\": \"tool\",\n",
    "\"name\": \"get_weather\",\n",
    "\"content\": weather_response,\n",
    "}\n",
    ")\n",
    "else:\n",
    "print(\"No tool calls were made by the model.\")\n",
    "\n",
    "# Final API request to the model\n",
    "final_response = client.chat.completions.create(\n",
    "model=\"gpt-4o\",\n",
    "messages=messages,\n",
    "temperature=0,\n",
    ")\n",
    "\n",
    "print(\"Final Response:\", final_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Tools Used by AI Agents\n",
    "- This section covers the contents of \"3.3 Tools Used by AI Agents\" in the book.\n",
    "- Only sections with code examples are listed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Tavily search tool\n",
    "tools = [TavilySearchResults(max_results=3, tavily_api_key=os.getenv(\"TAVILY_API_KEY\"))]\n",
    "tavily_tool = tools[0]\n",
    "\n",
    "# Search execution example\n",
    "query = \"AI Agent Practice Book\"\n",
    "results = tavily_tool.run(query)\n",
    "\n",
    "print(f\"Search query: {query}\")\n",
    "print(f\"Number of search results: {len(results)}\")\n",
    "print(\"\\nSearch results:\")\n",
    "for i, result in enumerate(results):\n",
    "print(f\"\\n{i+1}. Title: {result.get('title', 'N/A')}\")\n",
    "print(f\" URL: {result.get('url', 'N/A')}\")\n",
    "print(f\" Content: {result.get('content', 'N/A')[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define argument schema\n",
    "class AddArgs(BaseModel):\n",
    "a: int\n",
    "b: int\n",
    "\n",
    "@tool(args_schema=AddArgs)\n",
    "def add(a: int, b: int) -> int:\n",
    "\"\"\"\n",
    "This tool takes two integers as arguments and returns their sum.\n",
    "\n",
    "Args:\n",
    "a (int): The first integer to add.\n",
    "b (int): The second integer to add.\n",
    "\n",
    "Returns:\n",
    "int: The sum of the two integers.\n",
    "\n",
    "Usage example:\n",
    "Example:\n",
    "Input: {\"a\": 3, \"b\": 5}\n",
    "Output: 8\n",
    "\"\"\"\n",
    "return a + b\n",
    "\n",
    "# Example execution\n",
    "args = {\"a\": 5, \"b\": 10}\n",
    "result = add.func(**args) # Call the tool\n",
    "print(f\"Result: {result}\") # Result: 15\n",
    "\n",
    "# Check the attributes associated with a tool\n",
    "print(add.name)\n",
    "print(add.description)\n",
    "print(add.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of Duckduckgo's custom tooling using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDGSearchInput(BaseModel):\n",
    "\"\"\"Validates that the search query is a string.\n",
    "Search input of data types other than string is not accepted.\n",
    "\"\"\"\n",
    "\n",
    "query: str = Field(description=\"Enter search keywords\")\n",
    "\n",
    "@tool(args_schema=DDGSearchInput)\n",
    "def duckduckgo_search(query: str, max_result_num: int = 5) -> list[dict[str, str]]:\n",
    "\"\"\"\n",
    "This tool performs web searches using DuckDuckGo.\n",
    "\n",
    "Function:\n",
    "This tool performs a DuckDuckGo search for the specified keyword (query) and\n",
    "retrieves up to the specified number of results (max_result_num).\n",
    "Each search result includes a title, snippet, and URL.\n",
    "\n",
    "Args:\n",
    "query (str): Search keyword.\n",
    "max_result_num (int): Maximum number of search results to retrieve. Default is 5.\n",
    "\n",
    "Returns:\n",
    "List[Dict[str, str]]: A list of search results. Each element is a dictionary of the following format:\n",
    "- \"title\" (str): The title of the search result.\n",
    "- \"snippet\" (str): A snippet (summary) of the search result.\n",
    "- \"url\" (str): The URL of the search result.\n",
    "\"\"\"\n",
    "with DDGS() as ddgs:\n",
    "responce = ddgs.text(query, region=\"jp-jp\", safesearch=\"off\", backend=\"lite\")\n",
    "return [\n",
    "{\n",
    "\"title\": r.get(\"title\", \"\"),\n",
    "\"snippet\": r.get(\"body\", \"\"),\n",
    "\"url\": r.get(\"href\", \"\"),\n",
    "}\n",
    "for r in islice(responce, max_result_num)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a DuckDuckGo search\n",
    "search_query = \"AI Agent Practice Book\"\n",
    "search_results = duckduckgo_search.func(query=search_query, max_result_num=3)\n",
    "\n",
    "# Display search results\n",
    "print(\"\\nSearch results:\")\n",
    "for i, result in enumerate(search_results):\n",
    "print(f\"\\n{i + 1}. {result['title']}\")\n",
    "print(f\" Summary: {result['snippet'][:100]}...\")\n",
    "print(f\" URL: {result['url']}\")\n",
    "\n",
    "# Get the URL of the first search result\n",
    "if search_results:\n",
    "url = search_results[0][\"url\"]\n",
    "print(f\"\\nAccessing the URL of the first search result: {url}\")\n",
    "\n",
    "# Get the web page\n",
    "try:\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "print(f\"\\nHTTP status code: {response.status_code}\")\n",
    "print(f\"\\nHTML content size: {len(html_content)} bytes\")\n",
    "print(f\"\\nFirst part of HTML content: \\n{html_content[:500]}...\")\n",
    "except Exception as e:\n",
    "print(f\"\\nAn error occurred: {e}\")\n",
    "else:\n",
    "print(\"\\nNo search results found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Searching for non-public information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Before running the SQL database search below, please set up your PostgreSQL database environment.\n",
    "\n",
    "**Use the setup_postgres.sh script:**\n",
    "```bash\n",
    "# Run the setup script\n",
    "./setup_postgres.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the argument schema\n",
    "class SQLQueryArgs(BaseModel):\n",
    "keywords: str\n",
    "\n",
    "@tool(args_schema=SQLQueryArgs)\n",
    "def text_to_sql_search(keywords: str):\n",
    "\"\"\"\n",
    "Converts a natural language query into an SQL query and executes a search in an SQL database.\n",
    "\n",
    "Functionality:\n",
    "- This tool generates an SQL query based on given natural language keywords.\n",
    "- It uses LLM to generate SQL statements and executes a search in a PostgreSQL database.\n",
    "- It returns the search results.\n",
    "\n",
    "Args:\n",
    "keywords (str): The natural language keywords of the query you want to execute.\n",
    "Example: \"How many records are there in the employee table?\" \"\n",
    "\n",
    "Returns:\n",
    "Any: Returns database search results.\n",
    "\"\"\"\n",
    "try:\n",
    "# Set PostgreSQL database connection parameters\n",
    "# Use postgres-genai-ch3 container settings\n",
    "db_url = \"postgresql+psycopg2://testuser:testpass@localhost:5432/testdb\"\n",
    "db = SQLDatabase.from_uri(db_url)\n",
    "\n",
    "# LLM configuration\n",
    "llm = ChatOpenAI(\n",
    "api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "model=\"gpt-4o-mini\",\n",
    "temperature=0.0,\n",
    ")\n",
    "\n",
    "# SQL chain configuration\n",
    "db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)\n",
    "\n",
    "# Execution\n",
    "response = db_chain.run(keywords)\n",
    "return response\n",
    "\n",
    "except Exception as e:\n",
    "return f\"Error: Unable to connect to PostgreSQL database: {str(e)}\\n\\nSetup steps:\\n1. Run ./setup_postgres.sh in the chapter3 directory. 2. Verify that the PostgreSQL container is running.\n",
    "\n",
    "# Execution example\n",
    "args = {\"keywords\": \"How many records are there in the employee table?\"}\n",
    "text_to_sql_search.func(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Building an Agent Workflow with LangGraph\n",
    "- This section covers the contents of \"3.6 Building an Agent Workflow with LangGraph\" in the book.\n",
    "- Only sections with code examples are listed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2 How to build an agent workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. State and Workflow Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the agent workflow using LangGraph\n",
    "\n",
    "# Class for recording the state at the beginning of the workflow\n",
    "# This class is generally passed as an argument to each node.\n",
    "class AgentState(TypedDict):\n",
    "input: str # User input\n",
    "plans: list[str] # Plan node results\n",
    "feedbacks: list[str] # Retrospect node results\n",
    "output: str # Generate node results\n",
    "iteration: int\n",
    "\n",
    "# Define the entire graph\n",
    "workflow = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Setting up nodes and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building an agent workflow with LangGraph\n",
    "\n",
    "# Define the processing for each node and the conditional function for edges\n",
    "def plan_node(state: AgentState) -> AgentState:\n",
    "# Create a plan based on the current input\n",
    "plan = f\"Plan for creating blog post \"{state['input']}\":\"\n",
    "plans = state.get(\"plans\", [])\n",
    "plans.append(\n",
    "plan\n",
    "+ \"\\n1. Introduction\\n2. Basic Concepts of LangGraph\\n3. Simple Workflow Example\\n4. Conclusion\"\n",
    ")\n",
    "\n",
    "# Update the state and return\n",
    "return {**state, \"plans\": plans}\n",
    "\n",
    "def generation_node(state: AgentState) -> AgentState:\n",
    "# Generate output based on the plan\n",
    "iteration = state[\"iteration\"]\n",
    "# Increase the number of iterations\n",
    "iteration += 1\n",
    "\n",
    "# Get the current plan\n",
    "plan = state[\"plans\"][-1] if state[\"plans\"] else \"No plan\"\n",
    "\n",
    "# Generate output\n",
    "output = f\"Iteration Output for {iteration}:\\n\"\n",
    "if iteration == 1:\n",
    "output += \"# How to build an agent workflow using LangGraph\\n\\n## Introduction\\nLangGraph is a framework for building agents and workflows using large-scale language models (LLMs). \"\n",
    "elif iteration == 2:\n",
    "output += \"## Basic Concepts of LangGraph\\n\\n1. **State**: Information shared throughout the workflow\\n2. **Node**: Functions that perform processing\\n3. **Edge**: Connections between nodes and transition conditions\"\n",
    "elif iteration == 3:\n",
    "output += \"## LangGraph Implementation Example\\n\\n```python\\nfrom typing import TypedDict\\nfrom langgraph.graph import END, StateGraph, START\\n\\nclass AgentState(TypedDict):\\n input: str\\n output: str\\n```\"\n",
    "elif:\n",
    "output += \"## Summary\\n\\nLangGraph makes it easier to control complex agent behavior. Separating state management and workflow enables the development of maintainable AI applications. \"\n",
    "\n",
    "# Update state and return\n",
    "return {**state, \"output\": output, \"iteration\": iteration}\n",
    "\n",
    "def reflection_node(state: AgentState) -> AgentState:\n",
    "# Reflect on current output and generate feedback\n",
    "output = state[\"output\"]\n",
    "feedbacks = state.get(\"feedbacks\", [])\n",
    "\n",
    "# Generate feedback\n",
    "feedback = f\"feedback(iteration {state['iteration']}):\\n\"\n",
    "if state[\"iteration\"] == 1:\n",
    "feedback += \"The introduction is good, but it would be better to add more concrete examples and benefits.\"\n",
    "elif state[\"iteration\"] == 2:\n",
    "feedback += (\n",
    "\"The basic concepts are explained clearly. Adding code examples next would be helpful.\"\n",
    ")\n",
    "elif state[\"iteration\"] == 3:\n",
    "feedback += \"A code example is provided, but more detailed explanations and execution results would be helpful.\" \"\n",
    "\n",
    "feedbacks.append(feedback)\n",
    "\n",
    "# Update the state and return\n",
    "return {**state, \"feedbacks\": feedbacks}\n",
    "\n",
    "# Add the node to be used. Write the node name and corresponding function. The name must be unique, as it will be used later.\n",
    "workflow.add_node(\"planner\", plan_node)\n",
    "workflow.add_node(\"generator\", generation_node)\n",
    "workflow.add_node(\"reflector\", reflection_node)\n",
    "\n",
    "# Define the entry point. This is the first node to be called.\n",
    "workflow.add_edge(START, \"planner\")\n",
    "\n",
    "# Condition for the conditional edge. Iterate three times.\n",
    "def should_continue(state: AgentState):\n",
    "if state[\"iteration\"] > 3: # Iteration is an integer, so no len() is used.\n",
    "# End after 3 iterations\n",
    "return END\n",
    "return \"reflector\"\n",
    "\n",
    "# Add an edge connecting the nodes.\n",
    "workflow.add_edge(\"planner\", \"generator\")\n",
    "workflow.add_conditional_edges(\"generator\", should_continue, [\"reflector\", END])\n",
    "workflow.add_edge(\"reflector\", \"generator\")\n",
    "\n",
    "# Finally, compile the workflow. This will create a LangChain runnable format.\n",
    "# Once runnable, you can use invoke and stream.\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the agent workflow\n",
    "inputs = {\n",
    "\"input\": \"Write a blog post about building agent workflows using LangGraph\",\n",
    "\"iteration\": 0, # Set the initial iteration value\n",
    "\"plans\": [], # Set the initial plans value as well\n",
    "\"feedbacks\": [], # Set the initial feedback value as well\n",
    "\"output\": \"\", # Set the initial output value as well\n",
    "}\n",
    "\n",
    "for s in app.stream(inputs):\n",
    "print(list(s.values())[0])\n",
    "print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw with mermaid\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chapter3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
