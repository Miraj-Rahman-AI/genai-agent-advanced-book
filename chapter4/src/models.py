from pydantic import BaseModel, Field
from qdrant_client.models import ScoredPoint


class SearchOutput(BaseModel):
    """
    Structured representation of a single search result returned from either
    keyword-based search (Elasticsearch) or vector search (Qdrant).

    This model normalizes outputs from different search backends into a unified
    format so that downstream agents can process them consistently.
    """

    file_name: str = Field(description="Name of the source file where the content was found")
    content: str = Field(description="Extracted content or text snippet from the source file")

    @classmethod
    def from_hit(cls, hit: dict) -> "SearchOutput":
        """
        Convert an Elasticsearch search hit into a SearchOutput instance.

        Args:
            hit (dict):
                Raw search result from Elasticsearch. Expected to contain
                '_source' with 'file_name' and 'content'.

        Returns:
            SearchOutput:
                Normalized search output object.
        """
        return cls(
            file_name=hit["_source"]["file_name"],
            content=hit["_source"]["content"],
        )

    @classmethod
    def from_point(cls, point: ScoredPoint) -> "SearchOutput":
        """
        Convert a Qdrant vector search result (ScoredPoint) into SearchOutput.

        Args:
            point (ScoredPoint):
                Result returned by Qdrant containing vector match payload.

        Raises:
            ValueError:
                If payload is missing from the scored point.

        Returns:
            SearchOutput:
                Normalized search output object.
        """
        if point.payload is None:
            raise ValueError("Payload is None")

        return cls(
            file_name=point.payload["file_name"],
            content=point.payload["content"],
        )


class Plan(BaseModel):
    """
    Represents the planning output generated by the planning agent.

    The plan contains a list of subtasks required to fully answer the user's question.
    Each subtask is executed sequentially or in parallel by the agent workflow.
    """

    subtasks: list[str] = Field(
        ...,
        description="List of subtasks required to resolve the userâ€™s question"
    )


class ToolResult(BaseModel):
    """
    Represents the result of a single tool execution.

    This model records:
    - Which tool was used
    - What arguments were provided
    - What results were returned
    """

    tool_name: str = Field(..., description="Name of the tool that was executed")
    args: str = Field(..., description="Arguments passed to the tool")
    results: list[SearchOutput] = Field(..., description="Results returned by the tool")


class ReflectionResult(BaseModel):
    """
    Represents the reflection/evaluation result for a subtask execution.

    After a subtask answer is generated, the reflection step evaluates whether
    the answer sufficiently addresses the subtask. If not, corrective advice is given.
    """

    advice: str = Field(
        ...,
        description=(
            "If evaluation is NG (not sufficient), provide actionable advice such as "
            "trying another tool, rephrasing the query, or refining search keywords. "
            "Advice must not duplicate previous advice or overlap with other subtasks. "
            "Based on this advice, the system retries tool selection and execution."
        ),
    )

    is_completed: bool = Field(
        ...,
        description="Indicates whether the subtask has been successfully completed"
    )


class Subtask(BaseModel):
    """
    Represents the full lifecycle result of a single subtask.

    Includes:
    - Subtask description
    - Tool execution history
    - Reflection/evaluation history
    - Final subtask answer
    - Completion status
    - Number of retry attempts
    """

    task_name: str = Field(..., description="Name or description of the subtask")
    tool_results: list[list[ToolResult]] = Field(
        ...,
        description="History of tool execution results across attempts"
    )
    reflection_results: list[ReflectionResult] = Field(
        ...,
        description="Reflection/evaluation results for each attempt"
    )
    is_completed: bool = Field(
        ...,
        description="Indicates whether the subtask has been successfully completed"
    )
    subtask_answer: str = Field(
        ...,
        description="Final answer generated for this subtask"
    )
    challenge_count: int = Field(
        ...,
        description="Number of attempts made to complete the subtask"
    )


class AgentResult(BaseModel):
    """
    Final structured output returned by the HelpDesk agent.

    Contains:
    - Original user question
    - Generated plan
    - Results of all subtasks
    - Final synthesized answer
    """

    question: str = Field(..., description="Original user question")
    plan: Plan = Field(..., description="Generated execution plan")
    subtasks: list[Subtask] = Field(..., description="List of executed subtasks and their results")
    answer: str = Field(..., description="Final synthesized answer returned to the user")
